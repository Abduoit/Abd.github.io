<!DOCTYPE HTML>
<html>
  <head> 
    <!-- Google analytics tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-STGLQW4BJX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-STGLQW4BJX');
    </script>

    <!-- Title -->
    <title>Abdulrahman Al-Shanoon, Ph.D.</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">

    <!-- Isotope JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">

    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&display=swap" rel="stylesheet">
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&display=swap');
    </style>
  </head>

  <body id="body">

    <div id="main">
      <div id="intro">
        <div id="intro-text">
          <h1>Abdulrahman Al-Shanoon, Ph.D.</h1>
          <p>
            Hi there! I'm an AI/ML Scientist at <a href="https://www.gm.ca/en/home.html/"target="_blank" rel="noopener noreferrer">General Motors of Canada</a>, where I apply my expertise in artificial intelligence, machine learning, autonomous robotics, 
            computer vision, deep learning, reinforcement learning, and perception to innovate in advanced driver assistance system (ADAS) mapping and software development. I work with the Software Defined Vehicle (SDV) team 
            and the Mapping Software group to create and implement machine learning models for GM Map Management System (MMS), which is used by Super Cruise and Ultra Cruise programs.
            <div id="more-bio" style="display: none">
              <br>
              My passion for AI/ML stems from my academic background, where I obtained a PhD in AI, Robotics, and Automation Engineering from <a href="https://engineering.ontariotechu.ca/index.php/"target="_blank" rel="noopener noreferrer">Ontario Tech University</a>, Ontario, Canada,
              and a MS.c in Robotics Engineering from <a href="https://www.upm.edu.my/" target="_blank" rel="noopener noreferrer">Universiti Putra Malaysia</a>, Malaysia. I have multiple publications, certifications, and records of inventions in the field of AI/ML. I have developed and 
              implemented machine learning models for object detection and segmentation, self-learning strategy, path planning, obstacle avoidance, and robotic manipulation and grasping, using computer vision and reinforcement learning methods.
              I am motivated by the challenge and opportunity to advance the state-of-the-art in this domain and to contribute to the safety and efficiency of AI systems.
            </div>
            <br>
            <a href="javascript:toggle_bio()">Formal Bio</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <a href="https://">Github</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
            <a href="https://scholar.google.com/citations?hl=en&user=-3ixUdIAAAAJ&view_op=list_works&sortby=pubdate"target="_blank" rel="noopener noreferrer">Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/alshanoon/"target="_blank" rel="noopener noreferrer">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.youtube.com/@abdulrahmanal-shanoon9624/videos"target="_blank" rel="noopener noreferrer">YouTube</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://orcid.org/0000-0002-5120-3233/"target="_blank" rel="noopener noreferrer">ORCID</a>
            <br><br>
            aalshanoon at gmail dot com
            <br><br>
          </p>
        </div>
        <div id="intro-image">
          <img src="images/alshanoon.png">
          <div id="location">
            <span>üìç</span>
            <span>Toronto, ON, Canada</span>
          </div>
        </div>
      </div>

      <div id="filters" class="button-group">
        <!-- <button class="button" data-filter="*">Show All</button> -->
        <button class="button is-checked" data-filter=".highlight">Highlights</button>
        <button class="button" data-filter=".research">Research</button>
        <button class="button" data-filter=".publication">Publication</button>
        <button class="button" data-filter=".teaching">Teaching Experience</button>
        <button class="button" data-filter=".education">Education</button>
      </div>

      <div class="grid">

        <!-- Highlights -->
        <div class="list-item highlight description" data-category="highlight">
          Some highlights from our research:
        </div>

        <!-- Preview Videos -->
        <div class="list-item highlight previews" data-category="highlight">
          <video class="preview1" playsinline="" muted="" autoplay="" loop=""><source src="images/pick.mp4" type="video/mp4"></video>
          <video class="preview2" playsinline="" muted="" autoplay="" loop=""><source src="images/navigation.mp4" type="video/mp4"></video>
          <video class="preview3" playsinline="" muted="" autoplay="" loop=""><source src="images/pickplace2.mp4" type="video/mp4"></video>
          <video class="preview4" playsinline="" muted="" autoplay="" loop=""><source src="images/obj_detection.mp4" type="video/mp4"></video>
          <video class="preview5" playsinline="" muted="" autoplay="" loop=""><source src="images/husky.mp4" type="video/mp4"></video>
        </div>


        <!-- Research -->
        <div class="list-item research" data-category="research">
          <div class="research-item">
            <div class="research-video">
              <a href="https://www.youtube.com/watch?v=vHNC63Nrd3A&t=2s/"target="_blank" rel="noopener noreferrer"><video playsinline="" muted="" autoplay="" loop=""><source src="images/StG-30Sec.mp4" type="video/mp4"></video>
            </div>
            <div class="research-description">
              <h3>Smarter Robots: Learning to Make Sequential Decisions</h3>
              <p>Sequential decision-making issue is a challenging task in skilled robots. This paper takes a step towards solving the issue by introducing a self-learning strategy to 
                manipulate unknown objects in challenging scenarios based on minimal prior knowledge. The developed system learns jointly pre-grasping and grasping actions using model-free deep 
                reinforcement learning for robotic manipulation task.</p>
                <a href="https://link.springer.com/article/10.1007/s10846-022-01702-4/"target="_blank" rel="noopener noreferrer">From Choice to Action: Sequential Decisions in Robotics: PDF</a> </p>
            </div>
          </div>
          <div class="research-item">
            <div class="research-video">
              <a href="https://www.youtube.com/watch?v=JNSogWerPXI&t=75s/"target="_blank" rel="noopener noreferrer"><video playsinline="" muted="" autoplay="" loop=""><source src="images/pick.mp4" type="video/mp4"></video>
            </div>
            <div class="research-description">
              <h3>Grasping Unknown Objects: Robots Learning New Skills</h3>
              <p>Grasping unfamiliar objects (unknown during training) based on limited prior knowledge is a challenging task in robotic manipulation. 
                We introduce a robotic grasping strategy based on the model-free deep reinforcement learning, named Deep Reinforcement Grasp Policy. 
                The developed system demands minimal training time and limited simple objects in simulation and generalizes efficiently on novel objects in real-world scenario.</p>
                <a href="https://link.springer.com/article/10.1007/s11370-021-00380-9/"target="_blank" rel="noopener noreferrer">Beyond the Familiar: Robots Learning to Grasp Anything: PDF</a> </p>
            </div>
          </div>
          <div class="research-item">
            <div class="research-video">
              <a href="https://www.youtube.com/watch?v=-LSFgwv6I3o&t=3s/"target="_blank" rel="noopener noreferrer"><video playsinline="" muted="" autoplay="" loop=""><source src="images/tracking.mp4" type="video/mp4"></video>
            </div>
            <div class="research-description">
              <h3>Autonomous (8-DOF) Mobile Manipulators</h3>
              <p>The fourth industrial revolution (industry 4.0) demands high-autonomy and intelligence robotic manipulators. This work sets out to develop an autonomous 3D Visual Servoing system
                based on DeepNet, implemented in a sophisticated mobile manipulator system, and utilized single RGB image. Two main steps construct the entire system: first, perception network
                to estimate the pose of objects in 3D space. Second, the pose estimation data was then used in a 3D visual servoing scheme to control the motion of AMM system. </p>
                <a href="https://onlinelibrary.wiley.com/doi/full/10.1155/2022/3511265/"target="_blank" rel="noopener noreferrer">Industry 4.0 Calls for Highly Autonomous and Intelligent Manipulators: PDF</a> </p>
            </div>
          </div>

          <div class="research-item">
            <div class="research-video">
              <a href="https://www.youtube.com/watch?v=_fcpwH6CHKw/"target="_blank" rel="noopener noreferrer"><video playsinline="" muted="" autoplay="" loop=""><source src="images/vs.mp4" type="video/mp4"></video>
            </div>
            <div class="research-description">
              <h3>3D Visual Servoing and Deep Neural Networks for Robotic Manipulation</h3>
              <p>The critical challenge, for robot‚Äìobject-interaction, is to estimate visually the pose of the target object in a 3D space and combine it into a vision-based control scheme in manipulation applications.
                We proposes a novel reliable framework for deep ConvNet combined with visual servoing using a single RGB camera. We introduce an extensive system called Deep-Visual-Servoing (DVS) that addresses an integration of: 
                (I) training of deep-CNNs using synthetic dataset only and operates successfully in real-world scenario, (II) continuous 3 D object pose estimation as the sensing feedback in a 3D visual servoing control scheme.</p>
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S092188902200015X/"target="_blank" rel="noopener noreferrer">Deep-Visual-Servoing for Robotic Manipulation: PDF</a> </p>
            </div>
          </div>

          <div class="research-item">
            <div class="research-video">
              <a href="https://www.youtube.com/watch?v=EPlfd7YSh3k/"target="_blank" rel="noopener noreferrer"><video playsinline="" muted="" autoplay="" loop=""><source src="images/mvs.mp4" type="video/mp4"></video>
            </div>
            <div class="research-description">
              <h3>Position-Based Visual Servoing for Mobile Robot</h3>
              <p>Position-based visual servoing control system that is implemented in a Clearpath Husky mobile robot. The vision sensor used is a Kinect V1 by Microsoft. 
                The results are organized in to two separate tests; Straight and Steering. Both tests demonstrated the control systems ability to regulate the robots position and orientation to 
                the desired values.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/8439978/"target="_blank" rel="noopener noreferrer">Vision-Based Mobile Robot Control: PDF</a> </p>
            </div>
          </div>

        </div>


        <!-- Publications -->
        <div class="list-item publication" data-category="publication">
          <h2>Patent:</h2>
          <div class="patent-list">
            ‚Ä¢ Wind Monitoring System for A Vehicle. <a href="https://patents.google.com/patent/US20240359575A1/en?oq=US20240359575A1/" target="_blank" rel="noopener noreferrer">Google Patents</a>. P108471-PRI-NP-US01. 11/2024.<br>
            ‚Ä¢ Tandem Electric Vehicle Charging. P104086-PRI-NP-US01. 10/2024.<br>
            ‚Ä¢ Vehicle systems and methods for identification and deduplication of roadway objects P108591-PRI-NP-US01. 09/2024.<br>
            ‚Ä¢ Using Vehicle Sensor Inputs to Control Active Aero Devices. P105910-PRI-NP-US01. 10/2023.<br>
          </div>
          <h2>Research Publication:</h2>
          <div class="research-publication-list">
            <ul>
              <li>Tan, Aaron H., Al-Shanoon Abdulrahman, Haoxiang Lang, and Ying Wang. "MOBILE ROBOT DOCKING WITH OBSTACLE AVOIDANCE AND VISUAL SERVOING." International Journal of Robotics and Automation 38, no. 2 (2023).</li>
              <li>Al-Shanoon Abdulrahman, and Haoxiang Lang. "Learn to Grasp Unknown-Adjacent Objects for Sequential Robotic Manipulation." Journal of Intelligent & Robotic Systems 105, no. 4 (2022): 83.</li>
              <li>Al-Shanoon, Abdulrahman, Yanjun Wang, and Haoxiang Lang. "DeepNet-Based 3D Visual Servoing Robotic Manipulation." Journal of Sensors 2022 (2022).</li>
              <li>Al-Shanoon, Abdulrahman, and Haoxiang Lang. "Robotic manipulation based on 3-D visual servoing and deep neural networks." Robotics and Autonomous Systems 152 (2022): 104041.</li>
              <li>Al-Shanoon, Abdulrahman, and Haoxiang Lang. "Vision-Based Hand Gesture Recognition With Deep Machine Learning for Visual Servoing." In International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, vol. 51814, p. V05BT07A050. American Society of Mechanical Engineers, 2018.</li>
              <li>Al-Shanoon, Abdulrahman, Haoxiang Lang, and Ying Wang. "Learn to grasp unknown objects in robotic manipulation." Intelligent Service Robotics 14, no. 4 (2021): 571.</li>
              <li>Al-Shanoon, Abdulrahman. "Developing a mobile manipulation system to handle unknown and unstructured objects." PhD diss., 2021.</li>
              <li>Al-Shanoon, Abdulrahman, Aaron Hao Tan, Haoxiang Lang, and Ying Wang. "Mobile Robot Regulation with Position Based Visual Servoing." In 2018 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA), pp. 1-6. IEEE, 2018.</li>
              <li>Tan, Aaron, Al-Shanoon Abdulrahman, Haoxiang Lang, and Moustafa El-Gindy. "Mobile Robot Regulation With Image Based Visual Servoing." In International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, vol. 51807, p. V05AT07A078. American Society of Mechanical Engineers, 2018.</li>
              <li>Al-Shanoon, Abdulrahman, Siti Anom Ahmad, Mohd Hassan, and B. Khair. "Gripping an Object Based on Inspection of Slip Events for a Robotic Hand Model." Advanced Science Letters 23, no. 6 (2017): 5133-5137.</li>
              <li>Al-Shanoon, Abdulrahman, Siti Anom Ahmad, and Mohd Khair B. Hassan. "Re-gripping analysis based on implementation of slip-detection device for robotic hand model." In 2016 IEEE Region 10 Symposium (TENSYMP), pp. 203-206. IEEE, 2016.</li>
              <li>Al-Shanoon, Abdulrahman, Siti Anom Ahmad, and Mohd Khair B. Hassan. "Investigation of piezoresistive sensor for robotic gripping operations." In 2015 IEEE Student Symposium in Biomedical Engineering & Sciences (ISSBES), pp. 54-58. IEEE, 2015.</li>
              <li>Al-Shanoon, Abdulrahman, and Siti Anom Ahmad. "Slip detection with accelerometer and tactile sensors in a robotic hand model." In IOP Conference Series: Materials Science and Engineering, vol. 99, no. 1, p. 012001. IOP Publishing, 2015.</li>
              <li>Al-Shanoon, Abdulrahman, Siti Anom Ahmad, and Mohd Khair B. Hassan. "A susceptibility study on piezoresistive sensor in a pliable and rigid robotic claws model." (2015): 9106-Q111.</li>
              <li>Al-Shanoon, Abdulrahman. "Gripping controller design for a one-degree-of-freedom robotic hand model based on slip detection." M.Sc thesis, 2016.</li>
            </ul>
          </div>
        </div>

        <!-- Teaching Experience -->
        <div class="list-item teaching" data-category="teaching">
          <h2>Teaching Experience:</h2>
          <div class="teaching-list">
            <p><b>Teaching Assistant, Faculty of Engineering, Ontario Tech University, ON, Canada          
              <span style="float: right;">2017-2021</span></b><br>
            <ul>
              <li>Taught a range of engineering subjects: ‚ÄúDynamics, Introduction to Engineering, Robotics and Automation, Microprocessors and Digital Systems, Electromechanical Energy Conversion.‚Äù</li>
              <li>Contributed to the creation of methods and techniques for online teaching during the lockdown, which have now become the standard for virtual education practices.</li>
              <li>Provided instruction in diverse university-level classes.</li>
              <li>Oversaw the curriculum planning for undergraduate subjects.</li>
              <li>Graded assignments, midterms, and final exams for multiple courses.</li>
              <li>Developed class tutorials, lab materials, assignments, and exam questions.</li>
              <li>Held weekly consultation hours for students. Participated in weekly review meetings with the department supervisor.</li>
              <li>Formulated grading rubrics for coursework and examinations.</li>
            </ul>
            <br>

            <p><b>Laboratory Director at Dijlah University College, Iraq          
              <span style="float: right;">2011-2013</span></b><br>
            <ul>
              <li>In charge of Laboratory Official Digital Electronics and Software System.</li>
              <li>Teaching digital electronics and computer subjects to university level students.</li>
              <li>Compiled a project report with forward-looking recommendations and findings.</li>
              <li>Developed assignment modules for various chapters.</li>
              <li>Evaluated student comprehension and employed tailored teaching methods.</li>
              <li>Guided students through intricate numerical challenges. Marked students' exam papers.</li>
              <li>Guided students through the curriculum in preparation for their final exams.</li>
              <li>Monitored and adhered to the anticipated curriculum timelines.</li>
              <li>Fostered an engaging learning atmosphere through passion and enthusiasm.</li>
              <li>Acquired insights into the integration of educational theory and practical application.</li>
            </ul>
          </div>
        </div>

        <!-- Education -->
        <div class="list-item education" data-category="education">
          <h2>Education:</h2>
          <div class="education-list">
            <p><b>- Doctor of Philosophy (Ph.D.) - AI and Advanced Robotics. Ontario, Canada  
              <span style="float: right;">2017-2021</span></b><br>
              Faculty of Engineering, Ontario Tech University
            </p>
            <ul>
              <li>Thesis: <a href="https://ontariotechu.scholaris.ca/items/14df1c16-0966-455c-b2dd-a74befa0335d/" target="_blank" rel="noopener noreferrer">Developing a mobile manipulation system to handle unknown and unstructured objects.</a></li>
              <li>Research focused on AI, machine learning, and robotics manipulation.</li>
              <br>
            </ul>
            <p><b>- Master of Science (M.Sc.) - Robotics Engineering. Malaysia 
              <span style="float: right;">2014-2016</span></b><br>
              Faculty of Engineering, Universiti Putra Malaysia 
            </p>
            <ul>
              <li>Thesis: <a href="http://psasir.upm.edu.my/id/eprint/70461/" target="_blank" rel="noopener noreferrer">Gripping controller design for a one-degree-of-freedom robotic hand model based on slip detection.</a></li>
              <li>Research focused on robotics and automation.</li>
              <br>
            </ul>
            <p><b>- Bachelor of Engineering (B.Eng.) Honors: First Rank. Iraq 
              <span style="float: right;">2007-2011</span></b><br>
              Electrical & Electronics Engineering, Middle Technical University 
            </p>
            <ul>
              <li>Graduated with honors - First rank.</li>
              <br>

            </ul>
          </div>
        </div>

      </div>

      <div id="footer">&copy; Abdulrahman Al-Shanoon </div>

    </div>

    <script>

      // Isotope grid.
      var $grid = $('.grid').isotope({
        itemSelector: '.list-item',
        layoutMode: 'fitRows',
        transitionDuration: 0,
        stagger: 10,
        initLayout: false,
        getSortData: {
          name: '.name',
          symbol: '.symbol',
          number: '.number parseInt',
          category: '[data-category]',
          weight: function( itemElem ) {
            var weight = $( itemElem ).find('.weight').text();
            return parseFloat( weight.replace( /[\(\)]/g, '') );
          }
        }
      });

      // Bind filter button click.
      $('#filters').on( 'click', 'button', function() {
        var filterValue = $( this ).attr('data-filter');
        localStorage.setItem('filterValue', filterValue);
        $grid.isotope({ filter: filterValue });
      });

      // Change is-checked class on buttons.
      $('.button-group').each( function( i, buttonGroup ) {
        var $buttonGroup = $( buttonGroup );
        $buttonGroup.on( 'click', 'button', function() {
          $buttonGroup.find('.is-checked').removeClass('is-checked');
          $( this ).addClass('is-checked');
        });
      });

      function update_isotope() {
        // Retrieve cached button click.
        var defaultFilterValue = localStorage.getItem('filterValue');
        if (defaultFilterValue == null) {
          defaultFilterValue = ".highlight"
        }
        $grid.isotope({ filter: defaultFilterValue });
        var buttons = document.getElementsByClassName("button");
        for (var currButton of buttons) {
          if (currButton.getAttribute('data-filter') == defaultFilterValue) {
            currButton.classList.add('is-checked');
          } else {
            currButton.classList.remove('is-checked');
          }
        }
      }

      function toggle_bio() {
        var x = document.getElementById("more-bio");
        if (x.style.display === "none") {
          x.style.display = "block";
        } else {
          x.style.display = "none";
        }
      }

      function toggle_highlights() {
        var x = document.getElementById("main-highlights");
        var y = document.getElementById("more-highlights");
        var b = document.getElementById("toggle_highlights_button")
        if (y.style.display === "none") {
          x.style.display = "none";
          y.style.display = "block";
          b.innerHTML = "Show less"
          update_isotope();
        } else {
          x.style.display = "block";
          y.style.display = "none";
          b.innerHTML = "Show more"
          update_isotope();
        }
      }

      update_isotope();

    </script>
  </body>
</html>
